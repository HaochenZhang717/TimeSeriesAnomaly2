Train Epoch 0:   0%|                                                                                           | 0/482 [00:00<?, ?it/s]
> /Users/zhc/Documents/PhD/projects/TimeSeriesAnomaly/code/generation_models/DSPFlow/interpretable_flow/FMTS.py(203)_no_context_loss()
-> loss = loss.sum(dim=1) / (lengths.float() * C)
tensor([2.1479e+02, 2.4156e+02, 6.3398e+01, 5.4493e+02, 3.4843e+03, 1.3524e+03,
        2.6964e+02, 8.3408e+01, 1.6663e+03, 3.2944e+02, 9.7295e+02, 1.0592e+04,
        4.1839e+02, 1.0267e+03, 1.5247e+04, 1.9379e+03, 2.3506e+03, 2.1600e+03,
        3.8979e+02, 1.0034e+01, 2.5781e+03, 1.1989e+04, 1.8622e+03, 3.6133e+03,
        7.5346e+03, 1.7669e+04, 3.7668e+01, 1.8663e+03, 2.3468e+02, 6.6610e+01,
        8.1017e-01, 4.9524e+03, 4.3437e+03, 6.2977e+03, 2.5034e+03, 4.7544e+03,
        3.3635e+03, 2.1128e+03, 1.5876e+03, 2.0055e+02, 6.0359e+03, 4.4711e+01,
        1.0066e+03, 3.2462e+03, 2.8594e+04, 9.3443e+03, 4.5999e+03, 3.5600e+03,
        9.3544e+03, 1.2608e+03, 3.9267e+03, 6.4231e+02, 5.4852e+03, 1.3078e+03,
        1.4009e+04, 2.4854e+04, 1.9211e+03, 1.8578e+03, 9.0946e+03, 4.7838e+02,
        3.6136e+00, 1.7591e+03, 1.3633e+03, 4.9944e+03, 9.6689e+02, 6.5301e+03,
        1.4674e+03, 4.5409e+03, 4.7672e+03, 2.3299e+03, 1.6947e+02, 3.4446e+03,
        2.7927e+03, 4.2591e+01, 6.2114e+00, 2.4675e+01, 9.5499e+03, 8.0023e+02,
        2.6797e+00, 4.6131e+03, 5.2024e+03, 6.2967e+01, 4.6161e+03, 4.9725e+03,
        6.3984e+02, 8.5473e+02, 5.2139e+03, 1.3722e+04, 1.1546e+03, 2.7598e+03,
        5.4259e+03, 2.8692e+02, 3.3996e+03, 7.8071e+03, 4.0270e+03, 1.8276e+00,
        5.8641e+02, 1.6372e+04, 8.7440e+02, 3.8618e+02, 7.1009e+02, 3.1803e+01,
        2.0063e+01, 5.2310e+03, 1.8657e+03, 5.6998e+02, 1.0325e+01, 9.1714e+01,
        1.4280e+03, 1.9670e+02, 2.3566e+03, 2.0052e+02, 8.7620e+03, 2.4251e+02,
        2.6071e+02, 3.9954e+03, 5.3231e+02, 3.2385e+03, 8.9221e-01, 3.9310e+01,
        3.2605e+03, 1.0328e+03, 1.1123e+03, 2.8352e+02, 1.9338e+02, 9.7846e+01,
        5.6650e+01, 8.7670e+01, 1.1446e+03, 3.3574e+03, 2.3563e+02, 2.4408e+02,
        6.0909e+03, 1.4297e+00, 7.1106e+02, 5.7963e+03, 6.6274e+02, 2.8706e+03,
        4.4805e+03, 2.0255e+03, 4.1895e+01, 2.1141e+03, 5.9240e+03, 4.2784e+02,
        6.3472e+02, 3.6979e+03, 2.2128e+03, 8.8926e+01, 5.6635e+03, 1.4400e+01,
        1.3450e+03, 1.7326e+03, 8.5568e+02, 5.1119e+03, 1.2016e+01, 3.3394e+02,
        1.9922e+01, 2.4472e+03, 6.2986e+02, 5.8719e+02, 1.0031e+03, 1.5237e+03,
        5.8860e+00, 3.3536e+03, 1.2459e+00, 8.3736e+02, 3.9955e+02, 8.0942e+01,
        2.4151e+03, 1.3297e+03, 3.6294e+02, 7.7174e+03, 1.7482e+03, 2.3167e+00,
        8.4327e+02, 2.3955e+03, 4.2088e+01, 8.2239e+03, 2.0047e+03, 7.8784e+02,
        1.0273e+04, 3.9107e+00, 9.6849e+02, 4.8504e-01, 4.5451e+03, 8.4641e+02,
        4.0325e+02, 1.3472e+04, 2.1332e+02, 6.9443e+02, 8.1389e+03, 7.3796e+03,
        1.6028e+03, 1.3260e+02, 6.0917e+01, 1.2714e+03, 3.6778e+01, 6.7957e+01,
        1.4153e+03, 5.8932e+03, 5.3999e+03, 3.1498e+03, 4.6076e+01, 2.3070e+03,
        6.3448e+03, 2.5662e+02, 1.0818e+03, 6.0874e+03, 9.1356e+02, 1.6919e+02,
        2.6113e+04, 4.4417e+01, 8.5385e+03, 7.4555e+02, 6.8674e+03, 3.8610e+02,
        3.5805e+01, 2.2637e+02, 6.9866e+02, 5.2675e+03, 8.9634e+03, 2.0680e+03,
        1.1025e+04, 3.6231e+03, 2.1871e+02, 3.4108e+02, 1.0725e+03, 2.2561e+03,
        1.0497e+03, 5.6952e+03, 1.8415e+02, 1.6888e+03, 8.1712e+02, 2.1676e+04,
        1.0504e+03, 7.4890e+02, 3.9541e+03, 2.7194e+03, 6.8353e+03, 6.5326e+02,
        7.7861e+03, 6.4759e+02, 9.3973e+02, 1.3683e+04, 4.6259e+03, 2.9011e+02,
        4.1644e+02, 1.4658e+03, 5.8526e+03, 8.9282e+02, 4.7665e+03, 2.2241e+03,
        1.9489e+03, 1.1166e+03, 3.7611e+03, 1.1613e+03, 5.9815e+03, 6.9945e+01,
        7.7565e+01, 3.0146e+03, 1.2765e+03, 4.9025e+02, 3.1399e+02, 6.4170e+03,
        1.4135e+03, 6.8822e+02, 1.3540e+03, 9.3009e+02, 4.4151e+02, 1.5050e+02,
        3.3636e+03, 3.1255e+02, 6.5183e+03, 2.0670e+02, 5.4004e+01, 8.6109e+02,
        1.8908e+03, 1.0407e+03, 2.2954e+02, 3.4233e+02, 5.6864e+02, 5.0123e+00,
        1.8335e+03, 1.0000e+03, 3.1327e+03, 3.4217e+02, 8.4643e+02, 5.3360e+02,
        1.5656e+02, 6.8548e+02, 4.0481e+03, 1.2741e+03, 1.6702e+02, 1.4299e+03,
        5.4629e+03, 1.5387e+03, 1.6447e+01, 4.8634e+02, 1.4548e+03, 8.7220e+00,
        5.9358e+03, 3.1337e+03, 1.1175e+03, 6.4756e+03, 3.2432e+03, 5.8024e+03,
        1.0351e+02, 4.0473e+02, 5.4352e+03, 3.3245e+02, 6.1007e+03, 6.0112e+03,
        1.3143e+03, 2.1493e+03, 3.1174e+03, 4.7390e+03, 1.5058e+02, 9.7003e+01,
        1.0160e+03, 2.1801e+01, 2.0145e+02, 7.6266e+02, 3.6681e+01, 2.7599e+03,
        3.7800e+01, 3.7890e+02, 7.7249e+02, 2.5878e+03, 1.8486e+03, 2.4082e+03,
        4.9666e+02, 6.3493e+03, 3.0879e+03, 2.6719e+03, 3.2319e+03, 1.1708e+03,
        3.3696e+03, 2.4092e+03, 7.3984e+01, 8.4237e+03, 4.0984e+03, 3.3856e+03,
        8.2837e+03, 2.8682e+03, 5.5778e+02, 4.6625e+03, 1.7851e+04, 4.6261e+02,
        3.8092e+03, 3.6889e+03, 1.6155e+04, 2.5746e+00, 2.7934e+03, 8.8826e+03,
        1.9339e+03, 3.7960e+02, 6.0895e+03, 5.3156e+03, 1.3452e+03, 5.9658e+00,
        6.4336e+03, 1.2113e+03, 5.2932e+00, 1.7545e+03, 1.6521e+04, 5.5992e+02,
        1.0372e+01, 1.1105e+04, 9.0413e+02, 3.2352e+01, 3.1763e+01, 5.3185e+03,
        2.6579e+02, 1.3633e+03, 2.1009e+04, 1.7353e+03, 2.5582e+03, 4.6659e+03,
        1.0567e+04, 9.2068e+02, 1.2821e+03, 3.7148e+03, 1.2951e+03, 8.4568e+02,
        3.2681e+03, 7.4328e+03, 1.5178e+03, 1.4918e+00, 1.7907e+04, 4.1468e+03,
        4.5708e+02, 1.7277e+03, 2.0908e+03, 5.2543e+03, 8.1385e+02, 7.3369e+03,
        9.2991e+02, 8.1407e+01, 5.0525e+03, 1.0769e+04, 7.9665e+03, 4.0877e+02,
        1.4796e+03, 1.5540e+04, 1.6183e+03, 1.4487e+02, 3.7742e+03, 9.2199e+02,
        4.7768e+03, 6.6001e+03, 4.5503e+02, 3.3774e+03, 5.8741e+02, 1.2663e+03,
        3.7572e+01, 4.4123e+03, 2.9062e+00, 1.5504e+03, 1.5647e+04, 9.4389e+00,
        2.5660e+02, 6.5467e+03, 5.2767e+03, 1.3278e+03, 4.1272e+02, 6.0400e+02,
        1.0385e+03, 2.1453e+02, 3.5089e+02, 1.0422e+03, 7.1715e+02, 5.6876e+02,
        2.8184e+03, 4.6237e+02, 1.5398e+03, 8.5874e+02, 1.7012e+02, 4.7772e+01,
        1.9584e+03, 2.5998e+02, 1.1561e+03, 1.8980e+00, 4.8938e+01, 2.9249e+01,
        8.6394e+02, 3.3702e+01, 2.2581e+01, 3.1058e+02, 1.1996e+03, 3.5013e+02,
        2.7117e+02, 2.0815e+03, 9.6574e+02, 1.2750e+03, 1.3281e+03, 1.7787e+02,
        6.1355e+02, 4.2968e+02, 6.7792e+02, 6.2471e+02, 5.4912e+03, 2.1098e+03,
        1.3946e+03, 3.4114e+03, 1.0930e+03, 1.0596e+03, 9.1863e+03, 2.5148e+02,
        1.8022e+02, 2.2952e+03, 7.7965e+03, 5.3696e+02, 6.1665e+01, 3.8286e+01,
        1.8417e+02, 1.3437e+02, 6.7176e+03, 1.1791e+03, 6.1458e+02, 3.9510e+02,
        1.7124e+03, 4.1150e+03, 5.5985e+00, 6.2209e+03, 4.3825e+00, 1.0429e+03,
        1.4137e+03, 2.5617e+02, 3.5467e+02, 8.0118e+03, 4.9135e+00, 4.2470e+03,
        6.6073e+02, 8.7278e+03, 1.7842e+02, 1.8182e+03, 3.8990e+03, 1.6795e+01,
        4.0441e+03, 6.1015e+03, 3.1000e+01, 2.3137e+03, 1.0145e+04, 2.7504e+02,
        1.9404e+02, 1.5726e+04, 1.2904e+03, 2.0430e+01, 8.0657e+03, 5.4974e+02,
        1.2954e+03, 1.2586e+00, 1.1194e+04, 5.4030e+01, 2.3001e+02, 3.1015e+03,
        9.5300e+03, 8.0636e+02, 3.4165e+02, 7.9598e+03, 4.8933e+02, 3.4490e+02,
        8.0656e+02, 4.7767e+02, 1.8377e+03, 1.5256e+03, 5.2961e+03, 2.6714e+03,
        5.0365e+03, 3.7558e+03, 2.7873e+03, 1.3672e+03, 4.8055e+03, 1.0160e+03,
        2.9991e+02, 1.0503e+04, 4.7819e+02, 9.9402e+02, 1.5985e+04, 3.9450e+03,
        3.8611e+03, 2.1177e+03, 1.5014e+04, 1.6906e+02, 8.9797e+02, 3.2149e+03,
        6.4773e+03, 3.9906e+02, 2.8184e+03, 6.9887e+03, 2.9228e+01, 1.2167e+03,
        3.0594e+03, 1.8122e+03, 1.7847e+02, 8.2226e+02, 6.6122e+01, 1.2108e+03,
        6.1276e+02, 8.5967e+02, 2.2616e+03, 8.5537e+03, 2.2111e+02, 1.6372e+03,
        5.1700e+02, 1.6947e+03, 1.2264e+03, 3.1440e+03, 2.4129e+01, 2.7530e+03,
        5.5164e+03, 1.4833e+03, 6.0185e+01, 1.1639e+03, 2.3711e+03, 8.9829e+02,
        1.4315e+02, 4.5354e+03, 1.5077e+03, 1.1387e+03, 8.1869e+02, 8.2165e+02,
        3.6833e+01, 3.0225e-01, 8.2498e+03, 5.9584e+03, 8.6666e+00, 5.5854e+02,
        3.2512e-02, 1.4777e+02, 2.4497e+03, 1.7182e+01, 5.5077e+02, 7.9223e+01,
        1.8084e+03, 4.2010e+03, 4.5697e+02, 7.0642e+02, 9.4696e+02, 4.0280e+00,
        3.8320e+03, 7.8533e+03, 6.4699e+01, 1.3170e+02, 2.9892e+03, 9.7369e+02,
        8.1664e+03, 5.0930e+03, 1.4483e+03, 1.1190e+03, 7.9892e+03, 8.1315e+03,
        2.6809e+03, 4.4620e+03, 1.0301e+04, 2.0744e+02, 1.3065e+04, 9.3864e+03,
        5.4833e+02, 1.1797e+00, 7.4673e+03, 1.0421e+01, 1.4143e+03, 1.6916e+03,
        1.5893e+03, 7.2922e+01, 6.5205e+00, 3.7665e+03, 1.4708e+02, 4.8105e+03,
        2.1572e+03, 3.6141e+03, 8.2451e+01, 1.1875e+02, 4.5737e+01, 1.2131e+01,
        5.4513e+03, 2.5903e+02, 2.8108e+03, 3.4972e+00, 6.5393e+02, 1.2432e+02,
        4.2406e-02, 1.4299e+02, 5.6627e+03, 1.2296e+03, 1.2215e+02, 8.0449e+02,
        4.3645e+03, 1.3908e+04, 8.1532e+01, 3.7057e+03, 2.9365e+03, 1.4370e+02,
        5.0174e+03, 8.8528e+03, 4.0556e+03, 7.8579e+03, 2.4667e+02, 2.3039e+04,
        1.8291e+02, 3.5179e+02, 7.3699e+03, 1.1546e+02, 5.8612e+01, 1.5007e+04,
        8.4650e+03, 3.5209e+03, 9.0705e+02, 8.5475e+03, 7.6841e+03, 4.3936e+02,
        2.8346e+03, 3.1127e+02, 2.3725e+02, 3.6248e+03, 2.4850e+03, 6.8924e+02,
        2.4862e+03, 1.0764e+03, 1.0349e+04, 1.5554e+02, 2.5111e+03, 3.5844e+00,
        2.4345e+01, 2.1126e+03, 7.6644e+02, 4.2787e+03, 1.5710e+02, 4.7081e+03,
        1.7450e+03, 7.0736e+03, 4.9077e+03, 7.1934e+00, 6.1746e+03, 1.5088e+03,
        5.6980e+02, 9.7184e+03, 8.1395e+03, 1.7856e+01, 4.3815e+01, 1.1493e+04,
        3.9778e+00, 3.8109e+01, 6.2016e+03, 1.0253e+03, 2.1277e+03, 1.3446e+03,
        8.9276e+03, 7.5489e+01, 8.1385e+02, 3.1328e+01, 3.4721e+02, 2.8527e+03,
        1.1913e+03, 6.0973e+02, 1.4934e+04, 6.1165e+03, 2.1927e+03, 3.9121e+02,
        1.2584e+03, 1.6747e+04, 5.3946e+02, 6.3727e+02, 8.6848e+03, 1.2845e+03,
        4.7546e+03, 1.7579e+04, 1.6898e+04, 2.4297e+02, 2.3061e+03, 1.7610e+04,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,
        0.0000e+00, 0.0000e+00], grad_fn=<SelectBackward0>)
torch.Size([64, 800])
Traceback (most recent call last):
  File "/Users/zhc/Documents/PhD/projects/TimeSeriesAnomaly/code/dsp_flow.py", line 255, in <module>
    main()
  File "/Users/zhc/Documents/PhD/projects/TimeSeriesAnomaly/code/dsp_flow.py", line 233, in main
    no_context_pretrain(args)
  File "/Users/zhc/Documents/PhD/projects/TimeSeriesAnomaly/code/dsp_flow.py", line 219, in no_context_pretrain
    trainer.no_context_train(config=vars(args))
  File "/Users/zhc/Documents/PhD/projects/TimeSeriesAnomaly/code/Trainers/DSPFlow_trainer/trainer.py", line 59, in no_context_train
    loss = self.model(batch, mode="no_context")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/ColOCR_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/ColOCR_env/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/zhc/Documents/PhD/projects/TimeSeriesAnomaly/code/generation_models/DSPFlow/interpretable_flow/FMTS.py", line 158, in forward
    return self._no_context_loss(signals, attn_mask)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/zhc/Documents/PhD/projects/TimeSeriesAnomaly/code/generation_models/DSPFlow/interpretable_flow/FMTS.py", line 203, in _no_context_loss
    loss = loss.mean()
           ^^^^
  File "/opt/anaconda3/envs/ColOCR_env/lib/python3.12/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/anaconda3/envs/ColOCR_env/lib/python3.12/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
